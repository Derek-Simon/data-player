# Step1: Start Small

从小处着手，贪多嚼不烂。

用哪本教材，书籍，视频开始，其实不重要，重要的是**要上手**。



Tips: 找一本实战类型的，短小的书(不要超过300页)，全部实操一遍。



## 1. 选书

关键词：权威，短小，实战。



## 2. 第一遍: 快速浏览

> 第一遍略读，不要超过1个小时，有个大致印象即可，因为第二遍细度会完完整整的学习

我这里没办法照顾完全没有基础的人，因为不知道他们的状态。(我这样的口气只是因为我在使用“费曼学习法”)

做2件事：

1. 知道每个章节主要是在做什么
2. 找出技术关键词，大致作用以及他们的关系

用一张A4纸足够记录了。

![image-20211115131448983](assets/imgs/image-20211115131448983.png)

最关键的还是它的生态图: (不用全部记忆，记住纵向vertical部分即可)

![image-20211115132456865](assets/imgs/image-20211115132456865.png)

从上到下依次是(Pig, Hive) -> (HCatalog) -> (MapReduce) -> (YARN) -> HDFS.





## 3. 第二遍: 细读

其实就是建立知识框架，顺便把所有的 case 跑一遍.



这里都是一些非常细小、琐碎的步骤，演练，没有必要记录详细步骤，这里只记录 `CheckList` 和 `重点摘要`:

1. [Task CheckList](./task_list.md)
2. 核心摘要 (按章节划分)
   * [核心摘要C1](./main_core_01.md)
   * [核心摘要C2](./main_core_02.md)
   * [核心摘要C3](./main_core_03.md)
   * [核心摘要C4](./main_core_04.md)
   * [核心摘要C5](./main_core_05.md)
   * [核心摘要C6](./main_core_06.md)
   * [核心摘要C7](./main_core_07.md)
   * [核心摘要C8](./main_core_08.md)
   * [核心摘要C9](./main_core_09.md)

学习是一个螺旋、渐进的过程(就像我们开始学物理都是理想情况，到了大学才会研究实际情况)。如果前述(这里记录的)有不对的地方，在后续 Step 中进行 **覆盖式更新**，但不会对此处记录的内容进行更正，过去的终将成为历史。



## 4. 下阶段

首先它是 2016 年的书，其次它是V2版本，不用看，它讲述的部分内容肯定有过时的部分。

所以后面还要用最新版本的 Hadoop V3 再这样过一遍，V3版本内容理论上会比V2版本多，至少是有更新。

(下一阶段，不是一本书或者视频或者教材，**大概会涉及多项资料**)

